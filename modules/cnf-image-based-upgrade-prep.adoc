// Module included in the following assemblies:
// * edge_computing/cnf-image-based-upgrade-base.adoc

:_mod-docs-content-type: PROCEDURE
[id="ztp-image-based-upgrade-creating-configmap-resources-with-acm_{context}"]
= Creating ConfigMap objects for the image-based upgrade with {lcao}

The Lifecycle Agent needs all your OADP resources, extra manifests, and custom catalog sources wrapped in a `ConfigMap` objects to process them for the image-based upgrade.

.Prerequisites

* Generate a seed image from a compatible seed cluster.
* Create backup and restore resources.
* Create a separate partition on the target cluster for the container images that is shared between stateroots. For more information about, see _Additional resources_.
* Deploy a version of {lcao} that is compatible with the version used with the seed image.
* Install the OADP Operator, the `DataProtectionApplication` CR and its secret on the target cluster.
* Create an S3-compatible storage solution and a ready-to-use bucket with proper credentials configured. For more information, see _Additional resources_.

.Procedure

. Create your OADP `Backup` and `Restore` CRs in the same namespace where the OADP Operator is installed, which is `openshift-adp`.

. Filter for backup-specific CRs by using the `lca.openshift.io/apply-label` annotation in your `Backup` CRs. Based on which resources you define in the annotation, the {lcao} applies the `lca.openshift.io/backup: <backup_name>` label and adds the `labelSelector.matchLabels.lca.openshift.io/backup: <backup_name>` label selector to the specified resources when creating the `Backup` CRs.
+
--
[source,yaml]
----
apiVersion: velero.io/v1
kind: Backup
metadata:
  name: backup-acm-klusterlet <1>
  annotations:
    lca.openshift.io/apply-label: "apps/v1/deployments/open-cluster-management-agent/klusterlet,v1/secrets/open-cluster-management-agent/bootstrap-hub-kubeconfig,rbac.authorization.k8s.io/v1/clusterroles/klusterlet,v1/serviceaccounts/open-cluster-management-agent/klusterlet,scheduling.k8s.io/v1/priorityclasses/klusterlet-critical,rbac.authorization.k8s.io/v1/clusterroles/open-cluster-management:klusterlet-admin-aggregate-clusterrole,rbac.authorization.k8s.io/v1/clusterrolebindings/klusterlet,operator.open-cluster-management.io/v1/klusterlets/klusterlet,apiextensions.k8s.io/v1/customresourcedefinitions/klusterlets.operator.open-cluster-management.io,v1/secrets/open-cluster-management-agent/open-cluster-management-image-pull-credentials" <2>
  labels:
    velero.io/storage-location: default
  namespace: openshift-adp
spec:
  includedNamespaces:
  - open-cluster-management-agent
  includedClusterScopedResources:
  - klusterlets.operator.open-cluster-management.io
  - clusterroles.rbac.authorization.k8s.io
  - clusterrolebindings.rbac.authorization.k8s.io
  - priorityclasses.scheduling.k8s.io
  includedNamespaceScopedResources:
  - deployments
  - serviceaccounts
  - secrets
----
<1> The `acm-klusterlet` `Backup` and `Restore` CRs are specific to {rh-rhacm} environments only.
<2> The value must be a list of comma-separated objects in the `group/version/resource/name` format for cluster-scoped resources, or in the `group/version/resource/namespace/name` format for namespace-scoped resources. It must be attached to the related `Backup` CR.

[source,yaml]
----
apiVersion: velero.io/v1
kind: Backup
metadata:
  labels:
    velero.io/storage-location: default
  name: backup-example-app
  namespace: openshift-adp
spec:
  includedNamespaces:
  - test
  includedNamespaceScopedResources:
  - secrets
  - persistentvolumeclaims
  - deployments
  - statefulsets
  excludedClusterScopedResources:
  - persistentVolumes
----

[source,yaml]
----
apiVersion: velero.io/v1
kind: Restore
metadata:
  name: restore-acm-klusterlet <1>
  namespace: openshift-adp
  labels:
    velero.io/storage-location: default
  annotations:
    lca.openshift.io/apply-wave: "1"
spec:
  backupName:
    backup-acm-klusterlet
----
<1> The `acm-klusterlet` `Backup` and `Restore` CRs are specific to {rh-rhacm} environments only.

[source,yaml]
----
apiVersion: velero.io/v1
kind: Restore
metadata:
  name: restore-example-app
  namespace: openshift-adp
  labels:
    velero.io/storage-location: default
  annotations:
    lca.openshift.io/apply-wave: "2"
spec:
  backupName:
    backup-example-app
----

[NOTE]
====
Depending on your {rh-rhacm} configuration, you might need to include the `v1/secrets/open-cluster-management-agent/open-cluster-management-image-pull-credentials` object  for backup. If your `multiclusterHub` CR has `.spec.imagePullSecret` defined and the secret exists on the `open-cluster-management-agent` namespace in your hub cluster, ensure that the object is included in the `lca.openshift.io/apply-label` annotation. If the secret does not exist, you can remove the object from the apply-label annotation.
====

[IMPORTANT]
====
To use the `lca.openshift.io/apply-label` annotation for backing up specific resources, the resources listed in the annotation should also be included in the `spec` section.
If the `lca.openshift.io/apply-label` annotation is used in the `Backup` CR, only the resources listed in the annotation will be backed up, even if other resource types are specified in the `spec` section or not.
====
--

.. Define the apply order for the OADP Operator in the `Restore` CRs by using the `lca.openshift.io/apply-wave` field:
+
--
.Example OADP CRs
[source,yaml]
----
apiVersion: velero.io/v1
kind: Backup
metadata:
  labels:
    velero.io/storage-location: default
  name: backup-example-app
  namespace: openshift-adp
spec:
  includedNamespaces:
  - test
  includedNamespaceScopedResources:
  - secrets
  - persistentvolumeclaims
  - deployments
  - statefulsets
  excludedClusterScopedResources:
  - persistentVolumes
----

[source,yaml]
----
apiVersion: velero.io/v1
kind: Restore
metadata:
  name: restore-acm-klusterlet
  namespace: openshift-adp
  labels:
    velero.io/storage-location: default
  annotations:
    lca.openshift.io/apply-wave: "1"
spec:
  backupName:
    backup-acm-klusterlet
----

[source,yaml]
----
apiVersion: velero.io/v1
kind: Restore
metadata:
  name: restore-example-app
  namespace: openshift-adp
  labels:
    velero.io/storage-location: default
  annotations:
    lca.openshift.io/apply-wave: "2"
spec:
  backupName:
    backup-example-app
----

[NOTE]
====
If you do not define the `lca.openshift.io/apply-wave` annotation in the `Backup` or `Restore` CRs, they will be applied together.
====
--

. Generate a `ConfigMap` object for your OADP CRs.

.. Create the `ConfigMap` object:
+
[source,terminal]
----
$ oc create configmap example-oadp-cm --from-file=example-oadp-resources.yaml=<path_to_oadp_crs> -n openshift-adp
----

.. Apply the `ConfigMap`:
+
[source,terminal]
----
$ oc apply -f oadp-cm-example.yaml
----

. (Optional) Create `ConfigMap` resources that contain the additional manifests that you want to apply to the target cluster.

.. Create a YAML file that contains your extra manifestss.
+
[source,yaml]
----
apiVersion: sriovnetwork.openshift.io/v1
kind: SriovNetworkNodePolicy
metadata:
  name: "pci-sriov-net-e5l"
  namespace: openshift-sriov-network-operator
spec:
  deviceType: vfio-pci
  isRdma: false
  nicSelector:
    pfNames: [ens1f0]
  nodeSelector:
    node-role.kubernetes.io/master: ""
  mtu: 1500
  numVfs: 8
  priority: 99
  resourceName: pci_sriov_net_e5l
---
apiVersion: sriovnetwork.openshift.io/v1
kind: SriovNetwork
metadata:
  name: "networking-e5l"
  namespace: openshift-sriov-network-operator
spec:
  ipam: |-
    {
    }
  linkState: auto
  networkNamespace: flexran-testcases
  resourceName: pci_sriov_net_e5l
  spoofChk: "on"
  trust: "off"
----

.. Create the `ConfigMap` object:
+
[source,terminal]
----
$ oc create configmap example-extra-manifests-cm --from-file=example-extra-manifests.yaml=<path_to_extramanifest> -n openshift-lifecycle-agent
----

. (Optional) To keep your custom catalog sources after the upgrade, generate another `ConfigMap` object for your catalog sources and add them to the `spec.extraManifest` field in the `ImageBasedUpgrade` CR. For more information about catalog sources, see xref:https://access.redhat.com/documentation/en-us/openshift_container_platform/4.15/html-single/operators/index#olm-catalogsource_olm-understanding-olm[Catalog source].

.. Create a YAML file that contains the `CatalogSource` CR.
+
--
[source,yaml]
----
apiVersion: operators.coreos.com/v1alpha1
kind: CatalogSource
metadata:
  annotations:
    target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
  name: example-catalogsources
  namespace: openshift-marketplace
spec:
  sourceType: grpc
  displayName: disconnected-redhat-operators
  image: quay.io/example-org/example-catalog:v1
----
--

.. Create the `ConfigMap` object:
+
[source,terminal]
----
$ oc create configmap example-catalogsources-cm --from-file=example-catalogsources.yaml=<path_to_catalogsource_cr> -n openshift-lifecycle-agent
----

. Edit the `ImageBasedUpgrade` CR:
+
[source,yaml]
----
apiVersion: lca.openshift.io/v1alpha1
kind: ImageBasedUpgrade
metadata:
  name: example-upgrade
spec:
  stage: Idle
  seedImageRef:
    version: 4.15.2 <1>
    image: <seed_container_image> <2>
    pullSecretRef: <seed_pull_secret> <3>
  autoRollbackOnFailure: {}
#    initMonitorTimeoutSeconds: 1800 <4>
  extraManifests: <5>
  - name: example-extra-manifests-cm
    namespace: openshift-lifecycle-agent
  - name: example-catalogsources-cm
    namespace: openshift-lifecycle-agent
  oadpContent: <6>
  - name: oadp-cm-example
    namespace: openshift-adp
----
<1> Specify the target platform version. The value must match the version of the seed image.
<2> Specify the repository where the target cluster can pull the seed image from.
<3> Specify the reference to a secret with credentials to pull container images.
<4> (Optional) Specify the time frame in seconds to roll back if the upgrade does not complete within that time frame after the first reboot. If not defined or set to `0`, the default value of `1800` seconds (30 minutes) is used.
<5> (Optional) Specify the extra manifests to apply to the target cluster that are not part of the seed image. You can also add your custom catalog sources that you want to retain after the upgrade.
<6> Add the `oadpContent` section with the OADP `ConfigMap` information.

[id="ztp-image-based-upgrade-prep_{context}"]
= Moving to the Prep stage of the image-based upgrade with {lcao}

When you deploy the {lcao} on a cluster, an `ImageBasedUpgrade` CR is automatically created.
You edit this CR to specify the image repository of the seed image and to move through the different stages.

.Procedure

. When you are ready to start the `Prep` stage, change the value of the `stage` field to `Prep` in the `ImageBasedUpgrade` CR:
+
[source,terminal]
----
$ oc patch imagebasedupgrades.lca.openshift.io example-upgrade -p='{"spec": {"stage": "Prep"}}' --type=merge -n openshift-lifecycle-agent
----

+
The {lcao} checks for the health of the cluster, creates a new `ostree` stateroot, and pulls the seed image to the target cluster.
Then, the Operator precaches all the required images on the target cluster.

.Verification

. Check the status of the `ImageBasedUpgrade` CR.
+
[source,terminal]
----
$ oc get ibu -A -oyaml
----

+
.Example output
[source,yaml]
----
status:
  conditions:
  - lastTransitionTime: "2024-01-01T09:00:00Z"
    message: In progress
    observedGeneration: 2
    reason: InProgress
    status: "False"
    type: Idle
  - lastTransitionTime: "2024-01-01T09:00:00Z"
    message: 'Prep completed: total: 121 (pulled: 1, skipped: 120, failed: 0)'
    observedGeneration: 2
    reason: Completed
    status: "True"
    type: PrepCompleted
  - lastTransitionTime: "2024-01-01T09:00:00Z"
    message: Prep completed
    observedGeneration: 2
    reason: Completed
    status: "False"
    type: PrepInProgress
  observedGeneration: 2
----