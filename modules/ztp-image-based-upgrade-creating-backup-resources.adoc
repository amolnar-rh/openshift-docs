// Module included in the following assemblies:
// * scalability_and_performance/ztp-image-based-upgrade.adoc

:_mod-docs-content-type: PROCEDURE
[id="ztp-image-based-upgrade-creating-backup-resources_{context}"]
= Creating backup and restore resources with the OADP Operator

The {lcao} provides functionality for backing up and restoring platform and application resources with the OADP Operator.

You can specify the CRs you want to back up as `ConfigMap` objects in the `spec.oadpContent` section in the `ImageBasedUpgrade` CR. 

.Prerequisites

* Install the OADP Operator, the `DataProtectionApplication` CR and its secret on the target cluster.
* Create an S3-compatible storage solution and a ready-to-use bucket with proper credentials configured. For more information, see _Additional resources_.

.Procedure

This example procedure demonstrates how to back up and upgrade a cluster with applications which are using persistent volumes.

[NOTE]
====
The target cluster does not need to be detached from the hub cluster.
====

. Create your OADP `Backup` and `Restore` CRs in the same namespace where the OADP Operator is installed, which is `openshift-adp`.

.. To filter for backup-specific CRs, use the `lca.openshift.io/apply-label` annotation in your `Backup` CRs. Based on which resources you define in the annotation, the {lcao} applies the `lca.openshift.io/backup: <backup_name>` label and adds the `labelSelector.matchLabels.lca.openshift.io/backup: <backup_name>` label selector to the specified resources when creating the `Backup` CRs.
+
--
[source,yaml]
----
apiVersion: velero.io/v1
kind: Backup
metadata:
  name: backup-acm-klusterlet
  annotations:
    lca.openshift.io/apply-label: "apps/v1/deployments/open-cluster-management-agent/klusterlet,v1/secrets/open-cluster-management-agent/bootstrap-hub-kubeconfig,rbac.authorization.k8s.io/v1/clusterroles/klusterlet,v1/serviceaccounts/open-cluster-management-agent/klusterlet,rbac.authorization.k8s.io/v1/clusterroles/open-cluster-management:klusterlet-admin-aggregate-clusterrole,rbac.authorization.k8s.io/v1/clusterrolebindings/klusterlet,operator.open-cluster-management.io/v1/klusterlets/klusterlet,apiextensions.k8s.io/v1/customresourcedefinitions/klusterlets.operator.open-cluster-management.io,v1/secrets/open-cluster-management-agent/open-cluster-management-image-pull-credentials" <1>
  labels:
    velero.io/storage-location: default
  namespace: openshift-adp
spec:
  includedNamespaces:
  - open-cluster-management-agent
  includedClusterScopedResources:
  - klusterlets.operator.open-cluster-management.io
  - clusterclaims.cluster.open-cluster-management.io
  - clusterroles.rbac.authorization.k8s.io
  - clusterrolebindings.rbac.authorization.k8s.io
  includedNamespaceScopedResources:
  - deployments
  - serviceaccounts
  - secrets
----
<1> The value must be a list of comma-separated objects in the `group/version/resource/name` format for cluster-scoped resources, or in the `group/version/resource/namespace/name` format for namespace-scoped resources. It must be attached to the related `Backup` CR. 

[NOTE]
====
Depending on your {rh-rhacm} configuration, you might need to include the `v1/secrets/open-cluster-management-agent/open-cluster-management-image-pull-credentials` object  for backup. If your `multiclusterHub` CR has `.spec.imagePullSecret` defined and the secret exists on the `open-cluster-management-agent` namespace in your hub cluster, ensure that the object is included in the `lca.openshift.io/apply-label` annotation. If the secret does not exist, you can remove the object from the apply-label annotation.
====

[IMPORTANT]
====
To use the `lca.openshift.io/apply-label` annotation for backing up specific resources, the resources listed in the annotation should also be included in the `spec` section.
If the `lca.openshift.io/apply-label` annotation is used in the `Backup` CR, only the resources listed in the annotation will be backed up, even if other resource types are specified in the `spec` section or not.
====
--

.. Define the apply order for the OADP Operator in the `Backup` and `Restore` CRs by using the `lca.openshift.io/apply-wave` field:
+
--
[source,yaml]
----
apiVersion: velero.io/v1
kind: Backup
metadata:
  labels:
    velero.io/storage-location: default
  name: backup-example-app
  namespace: openshift-adp
spec:
  includedNamespaces:
  - test
  includedNamespaceScopedResources:
  - secrets
  - persistentvolumeclaims
  - deployments
  - statefulsets
  excludedClusterScopedResources:
  - persistentVolumes
---
apiVersion: velero.io/v1
kind: Restore
metadata:
  name: restore-acm-klusterlet
  namespace: openshift-adp
  labels:
    velero.io/storage-location: default
  annotations:
    lca.openshift.io/apply-wave: "1"
spec:
  backupName:
    backup-acm-klusterlet
---
apiVersion: velero.io/v1
kind: Restore
metadata:
  name: restore-example-app
  namespace: openshift-adp
  labels:
    velero.io/storage-location: default
  annotations:
    lca.openshift.io/apply-wave: "2"
spec:
  backupName:
    backup-example-app
----

[NOTE]
====
If you do not define the `lca.openshift.io/apply-wave` annotation in the `Backup` or `Restore` CRs, they will be applied together.
====
--

.. Create a `kustomization.yaml` that will append the information to a new `ConfigMap`:
+
[source,yaml]
----
configMapGenerator:
- name: oadp-cm-example
  namespace: openshift-adp
  files:
  - backup-acm-klusterlet.yaml
  - backup-example-app.yaml
  - restore-acm-klusterlet.yaml
  - restore-example-app.yaml
generatorOptions:
  disableNameSuffixHash: true <1>
----
<1> Disables the hash generation at the end of the `ConfigMap` filename which allows the `ConfigMap` file to be overwritten when a new one is generated with the same name.

.. Create the `ConfigMap`:
+
[source,terminal]
----
$ kustomize build ./ -o oadp-cm-example.yaml
----
+
.Example output
[source,terminal]
----
kind: ConfigMap
metadata:
  name: oadp-cm-example
  namespace: openshift-adp
[...]
----

.. If you are using {rh-rhacm}, apply the `ConfigMap`:
+
[source,terminal]
----
$ oc apply -f oadp-cm-example.yaml
----

.. If you are using GitOps ZTP, push the generated `ConfigMap` object to your git repository.

. (Optional) To keep your custom catalog sources after the upgrade, add them to the `spec.extraManifest` in the `ImageBasedUpgrade` CR. For more information, see xref:https://access.redhat.com/documentation/en-us/openshift_container_platform/4.15/html-single/operators/index#olm-catalogsource_olm-understanding-olm[Catalog source].

. Edit the `ImageBasedUpgrade` CR:
+
[source,yaml]
----
apiVersion: lca.openshift.io/v1alpha1
kind: ImageBasedUpgrade
metadata:
  name: example-upgrade
spec:
  stage: Idle
  seedImageRef:
    version: 4.15.2 <1>
    image: <seed_container_image> <2>
    pullSecretRef: <seed_pull_secret> <3>
  additionalImages:
    name: ""
    namespace: ""
  autoRollbackOnFailure: {} <4>
#    disabledForPostRebootConfig: "true" <5>
#    disabledForUpgradeCompletion: "true" <6>
#    disabledInitMonitor: "true" <7>
#    initMonitorTimeoutSeconds: 1800 <8>
#  extraManifests: <9>
#  - name: sno-extra-manifests
#    namespace: openshift-lifecycle-agent
  oadpContent: <10>
  - name: oadp-cm-example
    namespace: openshift-adp
----
<1> Specify the target platform version. The value must match the version of the seed image.
<2> Specify the repository where the target cluster can pull the seed image from.
<3> Specify the reference to a secret with credentials to pull container images.
<4> By default, automatic rollback on failure is enabled throughout the upgrade.
<5> (Optional) If set to `true`, this option disables automatic rollback when the reconfiguration of the cluster fails upon the first reboot.
<6> (Optional) If set to `true`, this option disables automatic rollback after the {lcao} reports a failed upgrade upon completion.
<7> (Optional) If set to `true`, this option disables automatic rollback when the upgrade does not complete after reboot within the time frame specified in the `initMonitorTimeoutSeconds` field.
<8> (Optional) Specifies the time frame in seconds. If not defined or set to `0`, the default value of `1800` seconds (30 minutes) is used.
<9> (Optional) Specify the extra manifests to apply to the target cluster that are not part of the seed image. You can also add your custom catalog sources that you want to retain after the upgrade.
<10> Add the `oadpContent` section with the OADP `ConfigMap` information.